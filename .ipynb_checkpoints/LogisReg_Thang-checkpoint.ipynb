{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a9a22a7-35f2-4579-bbd6-3b63d1f9dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from scipy import optimize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# tells matplotlib to embed plots within the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fe011a-d6f5-4575-9131-bb107ad1b67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "036da357-61ae-4b46-a820-ef733645ba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01fc862-bd4d-459d-a880-a9eb9cdc5912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23baafd-5499-4c7e-a16f-e02f4a83f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = pd.get_dummies(df['cp'], prefix = \"cp\")\n",
    "# b = pd.get_dummies(df['thal'], prefix = \"thal\")\n",
    "# c = pd.get_dummies(df['slope'], prefix = \"slope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c991d-4ea7-4c62-a8fd-0e8ba18576b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frames = [df, a, b, c]\n",
    "# df = pd.concat(frames, axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "222a5662-1f0e-4f9a-ad38-297c8b1a3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.target.values\n",
    "x_data = df.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e35de6d-6934-4a5e-9f03-d54aeefc80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "x = (x_data - np.min(x_data)) / (np.max(x_data) - np.min(x_data)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed176af-6abc-4aae-884e-f851e2eb9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4404f5d9-9850-4d47-b900-513f7455a58d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [24, 242]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7ad48eb91a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1342\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1345\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    829\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 831\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [24, 242]"
     ]
    }
   ],
   "source": [
    "accuracies = {}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train.T,y_train.T)\n",
    "acc = lr.score(x_test.T,y_test.T)*100\n",
    "\n",
    "accuracies['Logistic Regression'] = acc\n",
    "print(\"Test Accuracy {:.2f}%\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affe5176-3aa4-4562-aacf-e63276a572c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e733a9-2e71-4e3a-8e37-2ec8ecb786dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d249d-593a-417f-a2fd-dbc4aacacb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\n",
    "    z = np.array(z)\n",
    "    \n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    import math\n",
    "    g = 1 / (1 + math.e**(-z))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9648a-bab5-47c0-9654-33978c0e7b2f",
   "metadata": {},
   "source": [
    "## 1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a686af79-728a-4147-9bb9-21ee36485b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data matrix appropriately, and add ones for the intercept term\n",
    "m, n = x_train.shape\n",
    "\n",
    "# Add intercept term to X\n",
    "x_train = np.concatenate([np.ones((m, 1)), x_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0e0c0-71c8-468b-a604-44a6d940d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunction(theta, X, y):\n",
    "\n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    \n",
    "    ytp = np.transpose(y)\n",
    "    ttp = np.transpose(theta)\n",
    "    uni = (np.ones(y.shape))\n",
    "#     print((ytp * np.log(sigmoid(X * theta))))\n",
    "#     print(np.dot( X, theta))\n",
    "#     print(y)\n",
    "    m = np.size(X,0)\n",
    "    n = np.size(X,1)\n",
    "#     J = -1/m *  (y * np.log(sigmoid(np.dot( X, theta) + np.subtract(uni, y) * np.log(np.subtract(uni, sigmoid(np.dot( X, theta)))))))\n",
    "    \n",
    "    for i in range(m):\n",
    "        J += -1/m *  (y[i] * np.log(sigmoid(np.dot(ttp,X[i]))) + (1-y[i]) * np.log(1 - sigmoid(np.dot( ttp, X[i]))))\n",
    "       \n",
    "    for i in range(n):\n",
    "        tgrad = 0\n",
    "        for j in range(m):\n",
    "            tgrad += ( sigmoid(np.dot(ttp, X[j])) - y[j] ) * X[j,i]\n",
    "#             print (tgrad)\n",
    "        grad[i] = 1/m * tgrad\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8e9cf-ef18-46ce-9a35-e5266df9fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize fitting parameters\n",
    "# initial_theta = np.zeros(n+1)\n",
    "\n",
    "# cost, grad = costFunction(initial_theta, x_train, y_train)\n",
    "\n",
    "# # np.set_printoptions(precision=3)\n",
    "\n",
    "# print(len(grad))\n",
    "\n",
    "# print('Cost at initial theta (zeros): {:.3f}'.format(cost))\n",
    "\n",
    "# print('Gradient at initial theta (zeros):')\n",
    "# print(grad)\n",
    "\n",
    "\n",
    "# # Compute and display cost and gradient with non-zero theta\n",
    "# test_theta = np.ones(n+1) * 0.01\n",
    "# cost, grad = costFunction(test_theta, x_train, y_train)\n",
    "\n",
    "# print('Cost at test theta: {:.3f}'.format(cost))\n",
    "\n",
    "# print('Gradient at test theta:')\n",
    "# print(grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5be52c-462a-46cd-9d67-6a0292a3498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 400}\n",
    "\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_theta,\n",
    "                        (x_train, y_train),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# the fun property of `OptimizeResult` object returns\n",
    "# the value of costFunction at optimized theta\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized theta is  in the x property\n",
    "theta = res.x\n",
    "\n",
    "# Print theta to screen\n",
    "print(cost)\n",
    "\n",
    "print(theta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fe61bf-eab7-4c1b-84eb-d4a7e7d59895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba78b5-0d7f-4408-b033-f45ca785d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = x_test.shape\n",
    "x_test = np.concatenate([np.ones((m, 1)), x_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df86101-0955-4618-a838-f3fddfb02706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    \n",
    "    m = X.shape[0] # Number of training examples\n",
    "\n",
    "\n",
    "    p = np.zeros(m)\n",
    "\n",
    "\n",
    "    for i in range (m):\n",
    "        tmp = sigmoid(np.dot(np.transpose(theta), X[i]))\n",
    "#         print(tmp)\n",
    "#         print(\"-----------\" , i)\n",
    "        if (tmp < 0.5):\n",
    "            p[i] = 0\n",
    "        else:\n",
    "            p[i] = 1\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d595947e-6cd9-476b-b33a-7ffaff70536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy on our training set\n",
    "p = predict(theta, x_test)\n",
    "print('Train Accuracy: {:.2f} %'.format(np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fee413-164e-4f9e-9cd7-74df950ee616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (p)\n",
    "print (len(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0fd438-eae2-4f91-adb0-83cbdac1fc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test)\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08946a4-42d1-4884-a9d8-70ad7e5df131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def costFunctionReg(theta, X, y, lambda_):\n",
    "  \n",
    "    # Initialize some useful values\n",
    "    m = y.size  # number of training examples\n",
    "\n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    grad = np.zeros(theta.shape)\n",
    "\n",
    "    # ===================== YOUR CODE HERE ======================\n",
    "    \n",
    "    tmpT = 0\n",
    "    n = 0\n",
    "    n = np.size(theta, 0) \n",
    "    cost, grad = costFunction(theta, X, y)\n",
    "    for i in range (n):\n",
    "        if (i == 0):\n",
    "            continue\n",
    "        tmpT += theta[i] * theta[i]\n",
    "        \n",
    "        grad[i] = grad[i] + lambda_/m * theta[i]\n",
    "    J = cost + lambda_ * tmpT /(2*m)\n",
    "            \n",
    "    \n",
    "    # =============================================================\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69eae2ff-6c48-42af-afe4-fe4fb0683bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize fitting parameters\n",
    "initial_theta = np.zeros(x_train.shape[1])\n",
    "\n",
    "# Set regularization parameter lambda to 1 (you should vary this)\n",
    "lambda_ = 1\n",
    "\n",
    "# set options for optimize.minimize\n",
    "options= {'maxiter': 100}\n",
    "\n",
    "res = optimize.minimize(costFunctionReg,\n",
    "                        initial_theta,\n",
    "                        (x_train, y_train, lambda_),\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# the fun property of OptimizeResult object returns\n",
    "# the value of costFunction at optimized theta\n",
    "cost = res.fun\n",
    "\n",
    "# the optimized theta is in the x property of the result\n",
    "theta = res.x\n",
    "\n",
    "\n",
    "# Compute accuracy on our training set\n",
    "p = predict(theta, x_test)\n",
    "\n",
    "print('Train Accuracy: %.2f %%' % (np.mean(p == y_test) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08f68b-6123-4c9a-91b0-5348f43e1547",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
